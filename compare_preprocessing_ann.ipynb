{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handling import *\n",
    "from warnings import simplefilter\n",
    "import spectral\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras  # tf.keras\n",
    "import matplotlib as mpl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_handling:Root folder set to D:\\OneDriveFHNW\\FHNW\\EUT-P6bb-21HS-RS_M365 - General\\captures\n"
     ]
    }
   ],
   "source": [
    "spectral.settings.envi_support_nonlowercase_params = True\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "%matplotlib widget\n",
    "root = get_root_folder(\"PC\")\n",
    "root_training = root + \"/training\"\n",
    "root_references = root_training + \"/references\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = np.round(np.linspace(900,1700,224),1);\n",
    "RGB_BANDS = (81,131,181)\n",
    "\n",
    "BAND_LOW = 8\n",
    "BAND_HIGH = 210\n",
    "\n",
    "PLOT_LABELS = {\"index\": \"Wavelength [nm]\", \"value\": \"reflectance [1]\", \"variable\": \"pixel\"}\n",
    "COLUMN_NAMES = BANDS[BAND_LOW:BAND_HIGH]\n",
    "\n",
    "background_samples = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979210, 202)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Read Data\n",
    "plastic_data = pd.read_csv(\"./raw_data/mixed_plastics.csv\")\n",
    "compost_data = pd.read_csv(\"./raw_data/mixed_compost.csv\")\n",
    "background_data = pd.read_csv(\"./raw_data/background.csv\")\n",
    "\n",
    "fulldata = np.concatenate((plastic_data, compost_data, background_data))\n",
    "np.shape(fulldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((len(plastic_data)+len(compost_data)+len(background_data),3))\n",
    "labels[:len(plastic_data),0] = 1\n",
    "labels[len(plastic_data):len(plastic_data)+len(compost_data),1] = 1\n",
    "labels[len(plastic_data)+len(compost_data):,2] = 1\n",
    "\n",
    "plt.matshow(labels.T, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58600, 202)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load eval data\n",
    "\n",
    "plastic_data_eval = pd.read_csv(\"./raw_data/eval_plastics.csv\")\n",
    "compost_data_eval = pd.read_csv(\"./raw_data/eval_compost.csv\")\n",
    "background_data_eval = pd.read_csv(\"./raw_data/eval_bg.csv\")\n",
    "\n",
    "fulldata_eval = np.concatenate((plastic_data_eval, compost_data_eval, background_data_eval))\n",
    "np.shape(fulldata_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x221c28c9cf0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5404944c92734bc29fe51c47e0291bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=1600.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_eval = np.zeros((len(plastic_data_eval)+len(compost_data_eval)+len(background_data_eval),3))\n",
    "labels_eval[:len(plastic_data_eval),0] = 1\n",
    "labels_eval[len(plastic_data_eval):len(plastic_data_eval)+len(compost_data_eval),1] = 1\n",
    "labels_eval[len(plastic_data_eval)+len(compost_data_eval):,2] = 1\n",
    "\n",
    "plt.matshow(labels_eval.T, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fulldata_snv = snv_transform(fulldata)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "fulldata_scaled = scaler.fit_transform(fulldata)\n",
    "\n",
    "# Save scaler for use when predicting plastics later\n",
    "pickle.dump(scaler, open('scaler_no_transform.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open('scaler_no_transform.pkl', 'rb'))\n",
    "fulldata_eval_scaled_no_snv = scaler.transform(fulldata_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 96)                19488     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 48)                4656      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 147       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,291\n",
      "Trainable params: 24,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no_transform = keras.models.Sequential([\n",
    "        keras.layers.Input(202),\n",
    "        keras.layers.Dense(96, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(48, activation=\"relu\"),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "model_no_transform.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.8294 - accuracy: 0.6016 - val_loss: 0.7386 - val_accuracy: 0.6316\n",
      "Epoch 2/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.5449 - accuracy: 0.8546 - val_loss: 0.5814 - val_accuracy: 0.7704\n",
      "Epoch 3/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.3861 - accuracy: 0.8986 - val_loss: 0.4838 - val_accuracy: 0.7870\n",
      "Epoch 4/100\n",
      "1913/1913 [==============================] - 9s 4ms/step - loss: 0.2995 - accuracy: 0.9052 - val_loss: 0.4182 - val_accuracy: 0.8011\n",
      "Epoch 5/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.2496 - accuracy: 0.9130 - val_loss: 0.3604 - val_accuracy: 0.8177\n",
      "Epoch 6/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.2154 - accuracy: 0.9215 - val_loss: 0.3124 - val_accuracy: 0.8403\n",
      "Epoch 7/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1897 - accuracy: 0.9295 - val_loss: 0.2755 - val_accuracy: 0.8647\n",
      "Epoch 8/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.1702 - accuracy: 0.9366 - val_loss: 0.2424 - val_accuracy: 0.8879\n",
      "Epoch 9/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1545 - accuracy: 0.9425 - val_loss: 0.2182 - val_accuracy: 0.9034\n",
      "Epoch 10/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1415 - accuracy: 0.9476 - val_loss: 0.2024 - val_accuracy: 0.9111\n",
      "Epoch 11/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1313 - accuracy: 0.9518 - val_loss: 0.1827 - val_accuracy: 0.9209\n",
      "Epoch 12/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1229 - accuracy: 0.9552 - val_loss: 0.1716 - val_accuracy: 0.9258\n",
      "Epoch 13/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1153 - accuracy: 0.9584 - val_loss: 0.1605 - val_accuracy: 0.9311\n",
      "Epoch 14/100\n",
      "1913/1913 [==============================] - 9s 4ms/step - loss: 0.1086 - accuracy: 0.9610 - val_loss: 0.1528 - val_accuracy: 0.9343\n",
      "Epoch 15/100\n",
      "1913/1913 [==============================] - 9s 4ms/step - loss: 0.1036 - accuracy: 0.9630 - val_loss: 0.1446 - val_accuracy: 0.9390\n",
      "Epoch 16/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0986 - accuracy: 0.9650 - val_loss: 0.1394 - val_accuracy: 0.9410\n",
      "Epoch 17/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0944 - accuracy: 0.9671 - val_loss: 0.1281 - val_accuracy: 0.9483\n",
      "Epoch 18/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0910 - accuracy: 0.9682 - val_loss: 0.1253 - val_accuracy: 0.9487\n",
      "Epoch 19/100\n",
      "1913/1913 [==============================] - 7s 4ms/step - loss: 0.0880 - accuracy: 0.9692 - val_loss: 0.1218 - val_accuracy: 0.9502\n",
      "Epoch 20/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0849 - accuracy: 0.9708 - val_loss: 0.1160 - val_accuracy: 0.9529\n",
      "Epoch 21/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0824 - accuracy: 0.9717 - val_loss: 0.1170 - val_accuracy: 0.9519\n",
      "Epoch 22/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0800 - accuracy: 0.9728 - val_loss: 0.1107 - val_accuracy: 0.9552\n",
      "Epoch 23/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0777 - accuracy: 0.9738 - val_loss: 0.1082 - val_accuracy: 0.9565\n",
      "Epoch 24/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0754 - accuracy: 0.9747 - val_loss: 0.1021 - val_accuracy: 0.9599\n",
      "Epoch 25/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0738 - accuracy: 0.9755 - val_loss: 0.0982 - val_accuracy: 0.9624\n",
      "Epoch 26/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0724 - accuracy: 0.9760 - val_loss: 0.0946 - val_accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0706 - accuracy: 0.9768 - val_loss: 0.0928 - val_accuracy: 0.9660\n",
      "Epoch 28/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0692 - accuracy: 0.9773 - val_loss: 0.0919 - val_accuracy: 0.9665\n",
      "Epoch 29/100\n",
      "1913/1913 [==============================] - 7s 3ms/step - loss: 0.0679 - accuracy: 0.9780 - val_loss: 0.0904 - val_accuracy: 0.9673\n",
      "Epoch 30/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0666 - accuracy: 0.9784 - val_loss: 0.0872 - val_accuracy: 0.9689\n",
      "Epoch 31/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0654 - accuracy: 0.9788 - val_loss: 0.0868 - val_accuracy: 0.9692\n",
      "Epoch 32/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0645 - accuracy: 0.9790 - val_loss: 0.0848 - val_accuracy: 0.9703\n",
      "Epoch 33/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0635 - accuracy: 0.9795 - val_loss: 0.0819 - val_accuracy: 0.9715\n",
      "Epoch 34/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0622 - accuracy: 0.9799 - val_loss: 0.0820 - val_accuracy: 0.9715\n",
      "Epoch 35/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0617 - accuracy: 0.9801 - val_loss: 0.0812 - val_accuracy: 0.9720\n",
      "Epoch 36/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0611 - accuracy: 0.9803 - val_loss: 0.0799 - val_accuracy: 0.9725\n",
      "Epoch 37/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0601 - accuracy: 0.9807 - val_loss: 0.0787 - val_accuracy: 0.9730\n",
      "Epoch 38/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0792 - val_accuracy: 0.9727\n",
      "Epoch 39/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.0781 - val_accuracy: 0.9732\n",
      "Epoch 40/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0582 - accuracy: 0.9813 - val_loss: 0.0760 - val_accuracy: 0.9740\n",
      "Epoch 41/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0748 - val_accuracy: 0.9745\n",
      "Epoch 42/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0571 - accuracy: 0.9818 - val_loss: 0.0758 - val_accuracy: 0.9741\n",
      "Epoch 43/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0565 - accuracy: 0.9820 - val_loss: 0.0732 - val_accuracy: 0.9752\n",
      "Epoch 44/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0558 - accuracy: 0.9821 - val_loss: 0.0718 - val_accuracy: 0.9758\n",
      "Epoch 45/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0553 - accuracy: 0.9823 - val_loss: 0.0723 - val_accuracy: 0.9755\n",
      "Epoch 46/100\n",
      "1913/1913 [==============================] - 9s 4ms/step - loss: 0.0550 - accuracy: 0.9825 - val_loss: 0.0691 - val_accuracy: 0.9767\n",
      "Epoch 47/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.0544 - accuracy: 0.9828 - val_loss: 0.0700 - val_accuracy: 0.9765\n",
      "Epoch 48/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0541 - accuracy: 0.9829 - val_loss: 0.0700 - val_accuracy: 0.9764\n",
      "Epoch 49/100\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 0.0673 - val_accuracy: 0.9775\n",
      "Epoch 50/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0533 - accuracy: 0.9831 - val_loss: 0.0678 - val_accuracy: 0.9773\n",
      "Epoch 51/100\n",
      "1913/1913 [==============================] - 16s 8ms/step - loss: 0.0527 - accuracy: 0.9833 - val_loss: 0.0676 - val_accuracy: 0.9774\n",
      "Epoch 52/100\n",
      "1913/1913 [==============================] - 91s 48ms/step - loss: 0.0522 - accuracy: 0.9834 - val_loss: 0.0662 - val_accuracy: 0.9780\n",
      "Epoch 53/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.0664 - val_accuracy: 0.9780\n",
      "Epoch 54/100\n",
      "1913/1913 [==============================] - 45s 23ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.0673 - val_accuracy: 0.9776\n",
      "Epoch 55/100\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.0653 - val_accuracy: 0.9784\n",
      "Epoch 56/100\n",
      "1913/1913 [==============================] - 9s 4ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.0660 - val_accuracy: 0.9781\n",
      "Epoch 57/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0660 - val_accuracy: 0.9781\n",
      "Epoch 58/100\n",
      "1913/1913 [==============================] - 33s 17ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.0627 - val_accuracy: 0.9796\n",
      "Epoch 59/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.0644 - val_accuracy: 0.9787\n",
      "Epoch 60/100\n",
      "1913/1913 [==============================] - 51s 27ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.0650 - val_accuracy: 0.9786\n",
      "Epoch 61/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.0493 - accuracy: 0.9845 - val_loss: 0.0628 - val_accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S_no_transform\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "eval_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model_no_transform.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=2e-3),\n",
    "              metrics=[\"accuracy\"],)\n",
    "\n",
    "training_history = model_no_transform.fit(fulldata_scaled, labels, validation_data=(fulldata_eval_scaled_no_snv,labels_eval), epochs=100, callbacks=[tensorboard_callback, eval_callback], batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/model_no_transform\\assets\n"
     ]
    }
   ],
   "source": [
    "model_no_transform.save('./models/model_no_transform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth + SNV Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "fulldata_smoothed = savgol_filter(fulldata, window_length=15, polyorder=2,deriv=0)\n",
    "fulldata_snv = snv_transform(fulldata_smoothed)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "fulldata_snv_scaled = scaler.fit_transform(fulldata_snv)\n",
    "\n",
    "# Save scaler for use when predicting plastics later\n",
    "pickle.dump(scaler, open('scaler_snv.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open('scaler_snv.pkl', 'rb'))\n",
    "fulldata_eval_smooth = savgol_filter(fulldata_eval, window_length=15, polyorder=2,deriv=0)\n",
    "fulldata_eval_snv = snv_transform(fulldata_eval_smooth)\n",
    "fulldata_eval_snv_scaled = scaler.transform(fulldata_eval_snv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 96)                19488     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 48)                4656      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 147       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,291\n",
      "Trainable params: 24,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_snv = keras.models.Sequential([\n",
    "        keras.layers.Input(202),\n",
    "        keras.layers.Dense(96, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(48, activation=\"relu\"),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "model_snv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.5618 - accuracy: 0.7971 - val_loss: 0.4845 - val_accuracy: 0.8021\n",
      "Epoch 2/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.3382 - accuracy: 0.8908 - val_loss: 0.4544 - val_accuracy: 0.8135\n",
      "Epoch 3/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.3009 - accuracy: 0.9018 - val_loss: 0.4358 - val_accuracy: 0.8187\n",
      "Epoch 4/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.2805 - accuracy: 0.9076 - val_loss: 0.4197 - val_accuracy: 0.8208\n",
      "Epoch 5/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.2663 - accuracy: 0.9113 - val_loss: 0.4024 - val_accuracy: 0.8232\n",
      "Epoch 6/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.2545 - accuracy: 0.9140 - val_loss: 0.3912 - val_accuracy: 0.8250\n",
      "Epoch 7/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.2443 - accuracy: 0.9161 - val_loss: 0.3658 - val_accuracy: 0.8278\n",
      "Epoch 8/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.2341 - accuracy: 0.9184 - val_loss: 0.3453 - val_accuracy: 0.8316\n",
      "Epoch 9/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.2250 - accuracy: 0.9201 - val_loss: 0.3368 - val_accuracy: 0.8327\n",
      "Epoch 10/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.2155 - accuracy: 0.9220 - val_loss: 0.3175 - val_accuracy: 0.8366\n",
      "Epoch 11/100\n",
      "1913/1913 [==============================] - 9s 4ms/step - loss: 0.2068 - accuracy: 0.9241 - val_loss: 0.2908 - val_accuracy: 0.8437\n",
      "Epoch 12/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1977 - accuracy: 0.9268 - val_loss: 0.2727 - val_accuracy: 0.8515\n",
      "Epoch 13/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1886 - accuracy: 0.9301 - val_loss: 0.2473 - val_accuracy: 0.8682\n",
      "Epoch 14/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1804 - accuracy: 0.9340 - val_loss: 0.2254 - val_accuracy: 0.8839\n",
      "Epoch 15/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1724 - accuracy: 0.9378 - val_loss: 0.2081 - val_accuracy: 0.8949\n",
      "Epoch 16/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.1633 - accuracy: 0.9422 - val_loss: 0.1761 - val_accuracy: 0.9260\n",
      "Epoch 17/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.1557 - accuracy: 0.9454 - val_loss: 0.1621 - val_accuracy: 0.9350\n",
      "Epoch 18/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1478 - accuracy: 0.9487 - val_loss: 0.1479 - val_accuracy: 0.9451\n",
      "Epoch 19/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1413 - accuracy: 0.9514 - val_loss: 0.1329 - val_accuracy: 0.9578\n",
      "Epoch 20/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1351 - accuracy: 0.9541 - val_loss: 0.1199 - val_accuracy: 0.9675\n",
      "Epoch 21/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1300 - accuracy: 0.9558 - val_loss: 0.1122 - val_accuracy: 0.9685\n",
      "Epoch 22/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1250 - accuracy: 0.9581 - val_loss: 0.1031 - val_accuracy: 0.9722\n",
      "Epoch 23/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1204 - accuracy: 0.9598 - val_loss: 0.0961 - val_accuracy: 0.9755\n",
      "Epoch 24/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1167 - accuracy: 0.9613 - val_loss: 0.0911 - val_accuracy: 0.9765\n",
      "Epoch 25/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1133 - accuracy: 0.9624 - val_loss: 0.0857 - val_accuracy: 0.9770\n",
      "Epoch 26/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1098 - accuracy: 0.9637 - val_loss: 0.0805 - val_accuracy: 0.9801\n",
      "Epoch 27/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1070 - accuracy: 0.9646 - val_loss: 0.0765 - val_accuracy: 0.9792\n",
      "Epoch 28/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1045 - accuracy: 0.9657 - val_loss: 0.0741 - val_accuracy: 0.9819\n",
      "Epoch 29/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.1017 - accuracy: 0.9666 - val_loss: 0.0698 - val_accuracy: 0.9819\n",
      "Epoch 30/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0992 - accuracy: 0.9676 - val_loss: 0.0671 - val_accuracy: 0.9845\n",
      "Epoch 31/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0969 - accuracy: 0.9684 - val_loss: 0.0639 - val_accuracy: 0.9838\n",
      "Epoch 32/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0950 - accuracy: 0.9691 - val_loss: 0.0604 - val_accuracy: 0.9859\n",
      "Epoch 33/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0928 - accuracy: 0.9699 - val_loss: 0.0589 - val_accuracy: 0.9848\n",
      "Epoch 34/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0911 - accuracy: 0.9706 - val_loss: 0.0572 - val_accuracy: 0.9878\n",
      "Epoch 35/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0894 - accuracy: 0.9712 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
      "Epoch 36/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0877 - accuracy: 0.9718 - val_loss: 0.0518 - val_accuracy: 0.9879\n",
      "Epoch 37/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0860 - accuracy: 0.9724 - val_loss: 0.0518 - val_accuracy: 0.9884\n",
      "Epoch 38/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0844 - accuracy: 0.9731 - val_loss: 0.0501 - val_accuracy: 0.9893\n",
      "Epoch 39/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0824 - accuracy: 0.9739 - val_loss: 0.0472 - val_accuracy: 0.9891\n",
      "Epoch 40/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0809 - accuracy: 0.9743 - val_loss: 0.0452 - val_accuracy: 0.9895\n",
      "Epoch 41/100\n",
      "1913/1913 [==============================] - 9s 4ms/step - loss: 0.0794 - accuracy: 0.9748 - val_loss: 0.0447 - val_accuracy: 0.9900\n",
      "Epoch 42/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0783 - accuracy: 0.9751 - val_loss: 0.0477 - val_accuracy: 0.9909\n",
      "Epoch 43/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0768 - accuracy: 0.9758 - val_loss: 0.0413 - val_accuracy: 0.9913\n",
      "Epoch 44/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0759 - accuracy: 0.9763 - val_loss: 0.0414 - val_accuracy: 0.9907\n",
      "Epoch 45/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0745 - accuracy: 0.9767 - val_loss: 0.0398 - val_accuracy: 0.9916\n",
      "Epoch 46/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0738 - accuracy: 0.9769 - val_loss: 0.0389 - val_accuracy: 0.9915\n",
      "Epoch 47/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0726 - accuracy: 0.9773 - val_loss: 0.0417 - val_accuracy: 0.9922\n",
      "Epoch 48/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0718 - accuracy: 0.9776 - val_loss: 0.0398 - val_accuracy: 0.9921\n",
      "Epoch 49/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0709 - accuracy: 0.9777 - val_loss: 0.0357 - val_accuracy: 0.9923\n",
      "Epoch 50/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0700 - accuracy: 0.9782 - val_loss: 0.0354 - val_accuracy: 0.9919\n",
      "Epoch 51/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0689 - accuracy: 0.9787 - val_loss: 0.0368 - val_accuracy: 0.9931\n",
      "Epoch 52/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0680 - accuracy: 0.9788 - val_loss: 0.0345 - val_accuracy: 0.9931\n",
      "Epoch 53/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0677 - accuracy: 0.9789 - val_loss: 0.0344 - val_accuracy: 0.9931\n",
      "Epoch 54/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0666 - accuracy: 0.9793 - val_loss: 0.0331 - val_accuracy: 0.9933\n",
      "Epoch 55/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0663 - accuracy: 0.9793 - val_loss: 0.0323 - val_accuracy: 0.9931\n",
      "Epoch 56/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0654 - accuracy: 0.9798 - val_loss: 0.0326 - val_accuracy: 0.9937\n",
      "Epoch 57/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0646 - accuracy: 0.9799 - val_loss: 0.0340 - val_accuracy: 0.9936\n",
      "Epoch 58/100\n",
      "1913/1913 [==============================] - 7s 4ms/step - loss: 0.0638 - accuracy: 0.9802 - val_loss: 0.0340 - val_accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S_snv\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "eval_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model_snv.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=2e-3),\n",
    "              metrics=[\"accuracy\"],)\n",
    "\n",
    "training_history = model_snv.fit(fulldata_snv_scaled, labels, validation_data=(fulldata_eval_snv_scaled,labels_eval), epochs=100, callbacks=[tensorboard_callback, eval_callback], batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/model_snv\\assets\n"
     ]
    }
   ],
   "source": [
    "model_snv.save('./models/model_snv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth + Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "fulldata_deriv = savgol_filter(fulldata, window_length=15, polyorder=2,deriv=1)\n",
    "fulldata_snv = snv_transform(fulldata_deriv)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "fulldata_snv_scaled = scaler.fit_transform(fulldata_snv)\n",
    "\n",
    "# Save scaler for use when predicting plastics later\n",
    "pickle.dump(scaler, open('scaler_deriv_snv.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open('scaler_deriv_snv.pkl', 'rb'))\n",
    "fulldata_eval_deriv = savgol_filter(fulldata_eval, window_length=15, polyorder=2,deriv=1)\n",
    "fulldata_eval_snv = snv_transform(fulldata_eval_deriv)\n",
    "fulldata_eval_snv_scaled = scaler.transform(fulldata_eval_snv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 96)                19488     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 48)                4656      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 147       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,291\n",
      "Trainable params: 24,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_snv = keras.models.Sequential([\n",
    "        keras.layers.Input(202),\n",
    "        keras.layers.Dense(96, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(48, activation=\"relu\"),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "model_snv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: 0.7738 - accuracy: 0.7074 - val_loss: 0.5404 - val_accuracy: 0.8173\n",
      "Epoch 2/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.3757 - accuracy: 0.9012 - val_loss: 0.3467 - val_accuracy: 0.8268\n",
      "Epoch 3/100\n",
      "1913/1913 [==============================] - 16s 8ms/step - loss: 0.2483 - accuracy: 0.9237 - val_loss: 0.2532 - val_accuracy: 0.8689\n",
      "Epoch 4/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.1965 - accuracy: 0.9367 - val_loss: 0.1923 - val_accuracy: 0.9151\n",
      "Epoch 5/100\n",
      "1913/1913 [==============================] - 13s 7ms/step - loss: 0.1647 - accuracy: 0.9483 - val_loss: 0.1507 - val_accuracy: 0.9433\n",
      "Epoch 6/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.1428 - accuracy: 0.9571 - val_loss: 0.1185 - val_accuracy: 0.9670\n",
      "Epoch 7/100\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: 0.1269 - accuracy: 0.9625 - val_loss: 0.0977 - val_accuracy: 0.9775\n",
      "Epoch 8/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.1149 - accuracy: 0.9657 - val_loss: 0.0835 - val_accuracy: 0.9820\n",
      "Epoch 9/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.1060 - accuracy: 0.9680 - val_loss: 0.0737 - val_accuracy: 0.9853\n",
      "Epoch 10/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0990 - accuracy: 0.9697 - val_loss: 0.0663 - val_accuracy: 0.9879\n",
      "Epoch 11/100\n",
      "1913/1913 [==============================] - 11s 6ms/step - loss: 0.0930 - accuracy: 0.9710 - val_loss: 0.0594 - val_accuracy: 0.9886\n",
      "Epoch 12/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.0883 - accuracy: 0.9723 - val_loss: 0.0550 - val_accuracy: 0.9907\n",
      "Epoch 13/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.0840 - accuracy: 0.9736 - val_loss: 0.0529 - val_accuracy: 0.9925\n",
      "Epoch 14/100\n",
      "1913/1913 [==============================] - 13s 7ms/step - loss: 0.0800 - accuracy: 0.9748 - val_loss: 0.0491 - val_accuracy: 0.9931\n",
      "Epoch 15/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.0766 - accuracy: 0.9759 - val_loss: 0.0479 - val_accuracy: 0.9941\n",
      "Epoch 16/100\n",
      "1913/1913 [==============================] - 49s 26ms/step - loss: 0.0736 - accuracy: 0.9769 - val_loss: 0.0448 - val_accuracy: 0.9943\n",
      "Epoch 17/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.0709 - accuracy: 0.9777 - val_loss: 0.0415 - val_accuracy: 0.9945\n",
      "Epoch 18/100\n",
      "1913/1913 [==============================] - 15s 8ms/step - loss: 0.0683 - accuracy: 0.9785 - val_loss: 0.0434 - val_accuracy: 0.9954\n",
      "Epoch 19/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0662 - accuracy: 0.9794 - val_loss: 0.0380 - val_accuracy: 0.9952\n",
      "Epoch 20/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0641 - accuracy: 0.9802 - val_loss: 0.0375 - val_accuracy: 0.9954\n",
      "Epoch 21/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0623 - accuracy: 0.9807 - val_loss: 0.0404 - val_accuracy: 0.9959\n",
      "Epoch 22/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.0389 - val_accuracy: 0.9960\n",
      "Epoch 23/100\n",
      "1913/1913 [==============================] - 11s 6ms/step - loss: 0.0587 - accuracy: 0.9819 - val_loss: 0.0357 - val_accuracy: 0.9961\n",
      "Epoch 24/100\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: 0.0572 - accuracy: 0.9825 - val_loss: 0.0338 - val_accuracy: 0.9960\n",
      "Epoch 25/100\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: 0.0559 - accuracy: 0.9830 - val_loss: 0.0385 - val_accuracy: 0.9961\n",
      "Epoch 26/100\n",
      "1913/1913 [==============================] - 9s 5ms/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 0.0343 - val_accuracy: 0.9963\n",
      "Epoch 27/100\n",
      "1913/1913 [==============================] - 8s 4ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 0.0340 - val_accuracy: 0.9963\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S_snv_deriv\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "eval_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model_snv.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=2e-3),\n",
    "              metrics=[\"accuracy\"],)\n",
    "\n",
    "training_history = model_snv.fit(fulldata_snv_scaled, labels, validation_data=(fulldata_eval_snv_scaled,labels_eval), epochs=100, callbacks=[tensorboard_callback, eval_callback], batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/model_snv_deriv\\assets\n"
     ]
    }
   ],
   "source": [
    "model_snv.save('./models/model_snv_deriv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ea3dadd995743c070a60538d12e65af98266bdc8fe22fa5ff7f84eb82e6fdd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
